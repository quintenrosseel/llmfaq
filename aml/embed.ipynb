{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Embedder\n",
        "\n",
        "Embed chunked content with a high-recall tuned language model. For now, we're using the `HuggingFaceInstructEmbeddings`.\n",
        "\n",
        "**Note**\n",
        "- Run this notebook with an appropriate compute. \n",
        "- The code below installs the necessary requirements. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y sentence-transformers==2.2.2\n",
        "!pip install sentence-transformers==2.2.2 --no-cache-dir"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing installation: sentence-transformers 2.2.2\nUninstalling sentence-transformers-2.2.2:\n  Successfully uninstalled sentence-transformers-2.2.2\nCollecting sentence-transformers==2.2.2\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[K     |████████████████████████████████| 85 kB 5.0 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sentence-transformers==2.2.2) (4.16.0)\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sentence-transformers==2.2.2) (4.65.0)\nRequirement already satisfied: torch>=1.6.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sentence-transformers==2.2.2) (1.12.0)\nRequirement already satisfied: torchvision in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sentence-transformers==2.2.2) (0.9.1)\nRequirement already satisfied: numpy in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sentence-transformers==2.2.2) (1.21.6)\nRequirement already satisfied: scikit-learn in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sentence-transformers==2.2.2) (0.22.1)\nRequirement already satisfied: scipy in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sentence-transformers==2.2.2) (1.5.3)\nRequirement already satisfied: nltk in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sentence-transformers==2.2.2) (3.8.1)\nRequirement already satisfied: sentencepiece in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sentence-transformers==2.2.2) (0.1.99)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sentence-transformers==2.2.2) (0.14.1)\nRequirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2023.5.5)\nRequirement already satisfied: requests in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2.31.0)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (23.0)\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (3.12.0)\nRequirement already satisfied: sacremoses in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.0.53)\nRequirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.13.3)\nRequirement already satisfied: typing-extensions in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (4.6.0)\nRequirement already satisfied: pillow>=4.1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from torchvision->sentence-transformers==2.2.2) (9.2.0)\nRequirement already satisfied: joblib>=0.11 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-learn->sentence-transformers==2.2.2) (1.2.0)\nRequirement already satisfied: click in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from nltk->sentence-transformers==2.2.2) (8.1.3)\nRequirement already satisfied: fsspec in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.5.0)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (1.26.16)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (3.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2022.9.24)\nRequirement already satisfied: six in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (1.16.0)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=246e5ba547c51e56c50ba60d24952cd61351b26a9766ef404afce6a3389fac0f\n  Stored in directory: /tmp/pip-ephem-wheel-cache-oga0wbnh/wheels/5e/6f/8c/d88aec621f3f542d26fac0342bef5e693335d125f4e54aeffe\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.2.2\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700296891825
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y sentence-transformers\n",
        "!pip install -U sentence-transformers --no-cache-dir"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing installation: sentence-transformers 2.2.2\nUninstalling sentence-transformers-2.2.2:\n  Successfully uninstalled sentence-transformers-2.2.2\nCollecting sentence-transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[K     |████████████████████████████████| 85 kB 5.0 MB/s eta 0:00:011\n\u001b[?25hRequirement already satisfied, skipping upgrade: transformers<5.0.0,>=4.6.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sentence-transformers) (4.16.0)\nRequirement already satisfied, skipping upgrade: tqdm in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sentence-transformers) (4.65.0)\nRequirement already satisfied, skipping upgrade: torch>=1.6.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sentence-transformers) (1.12.0)\nRequirement already satisfied, skipping upgrade: torchvision in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sentence-transformers) (0.9.1)\nRequirement already satisfied, skipping upgrade: numpy in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sentence-transformers) (1.21.6)\nRequirement already satisfied, skipping upgrade: scikit-learn in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sentence-transformers) (0.22.1)\nRequirement already satisfied, skipping upgrade: scipy in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sentence-transformers) (1.5.3)\nRequirement already satisfied, skipping upgrade: nltk in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sentence-transformers) (3.8.1)\nRequirement already satisfied, skipping upgrade: sentencepiece in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sentence-transformers) (0.1.99)\nRequirement already satisfied, skipping upgrade: huggingface-hub>=0.4.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sentence-transformers) (0.14.1)\nRequirement already satisfied, skipping upgrade: sacremoses in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.53)\nRequirement already satisfied, skipping upgrade: pyyaml>=5.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0)\nRequirement already satisfied, skipping upgrade: requests in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.31.0)\nRequirement already satisfied, skipping upgrade: filelock in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.12.0)\nRequirement already satisfied, skipping upgrade: packaging>=20.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (23.0)\nRequirement already satisfied, skipping upgrade: tokenizers!=0.11.3,>=0.10.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\nRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.5.5)\nRequirement already satisfied, skipping upgrade: typing-extensions in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from torch>=1.6.0->sentence-transformers) (4.6.0)\nRequirement already satisfied, skipping upgrade: pillow>=4.1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from torchvision->sentence-transformers) (9.2.0)\nRequirement already satisfied, skipping upgrade: joblib>=0.11 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-learn->sentence-transformers) (1.2.0)\nRequirement already satisfied, skipping upgrade: click in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from nltk->sentence-transformers) (8.1.3)\nRequirement already satisfied, skipping upgrade: fsspec in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.5.0)\nRequirement already satisfied, skipping upgrade: six in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.16.0)\nRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.9.24)\nRequirement already satisfied, skipping upgrade: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.1.0)\nRequirement already satisfied, skipping upgrade: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.4)\nRequirement already satisfied, skipping upgrade: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.26.16)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=c7d65dc041da6311299175aab42d7917563c37d75f80f01ee560d63e493bc3ae\n  Stored in directory: /tmp/pip-ephem-wheel-cache-3myjvoym/wheels/5e/6f/8c/d88aec621f3f542d26fac0342bef5e693335d125f4e54aeffe\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.2.2\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700298347480
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y InstructorEmbedding==1.0.1\n",
        "!pip install InstructorEmbedding==1.0.1 --no-cache-dir\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing installation: InstructorEmbedding 1.0.1\nUninstalling InstructorEmbedding-1.0.1:\n  Successfully uninstalled InstructorEmbedding-1.0.1\nCollecting InstructorEmbedding==1.0.1\n  Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\nInstalling collected packages: InstructorEmbedding\nSuccessfully installed InstructorEmbedding-1.0.1\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700298040469
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neo4j"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y azure-identity azure-keyvault-secrets azure-keyvault\n",
        "!pip install azure-identity azure-keyvault-secrets azure-keyvault"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y langchain\n",
        "!pip install langchain"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[33mWARNING: Skipping langchain as it is not installed.\u001b[0m\nCollecting langchain\n  Using cached langchain-0.0.337-py3-none-any.whl (2.0 MB)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (8.2.2)\nRequirement already satisfied: numpy<2,>=1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (1.21.6)\nRequirement already satisfied: anyio<4.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (3.6.2)\nRequirement already satisfied: pydantic<3,>=1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (1.10.8)\nRequirement already satisfied: PyYAML>=5.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (6.0)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (3.8.4)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (1.33)\nRequirement already satisfied: requests<3,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (2.31.0)\nRequirement already satisfied: langsmith<0.1.0,>=0.0.63 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (0.0.65)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (2.0.23)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (4.0.2)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (0.6.2)\nRequirement already satisfied: idna>=2.8 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from anyio<4.0->langchain) (3.4)\nRequirement already satisfied: sniffio>=1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from anyio<4.0->langchain) (1.3.0)\nRequirement already satisfied: typing-extensions>=4.2.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pydantic<3,>=1->langchain) (4.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\nRequirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\nRequirement already satisfied: jsonpointer>=1.9 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2->langchain) (2022.9.24)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2->langchain) (1.26.16)\nRequirement already satisfied: greenlet!=0.4.17; platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\"))))) in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\nRequirement already satisfied: packaging>=17.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.0)\nInstalling collected packages: langchain\nSuccessfully installed langchain-0.0.337\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Credentials"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.keyvault.secrets import SecretClient\n",
        "\n",
        "key_vault_name = \"kv-bsauwmno\"\n",
        "kv_uri = f\"https://{key_vault_name}.vault.azure.net/\"\n",
        "\n",
        "credential = DefaultAzureCredential()\n",
        "client = SecretClient(vault_url=kv_uri, credential=credential)\n",
        "\n",
        "# Now you can use neo4j_url, neo4j_port, and neo4j_password in your application\n",
        "neo4j_url = client.get_secret(\"NEO4JURL\").value\n",
        "neo4j_user = client.get_secret(\"NEO4JUSER\").value\n",
        "neo4j_password = client.get_secret(\"NEO4JPASSWORD\").value"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700296921240
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "langchain.verbose = True\n",
        "langchain.debug = True"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700298806128
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read from pikle file\n",
        "chunks_raw_df = pd.read_pickle('./data/chunks_raw.pkl')\n",
        "\n",
        "chunks_raw_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "                                             content  \\\n0  \\n## Waarom willen de kinderartsen dat je baby...   \n0  \\n## Waarom willen de kinderartsen dat je baby...   \n0  \\n## Waarom willen de kinderartsen dat je baby...   \n0  \\n## Waarom willen de kinderartsen dat je baby...   \n0  \\n## Waarom willen de kinderartsen dat je baby...   \n\n                           banner_title  \\\n0  24 uur observatie van de pasgeborene   \n0  24 uur observatie van de pasgeborene   \n0  24 uur observatie van de pasgeborene   \n0  24 uur observatie van de pasgeborene   \n0  24 uur observatie van de pasgeborene   \n\n                                    banner_divisions  \\\n0  [{'division_url': 'https://www.azstlucas.be/sp...   \n0  [{'division_url': 'https://www.azstlucas.be/sp...   \n0  [{'division_url': 'https://www.azstlucas.be/sp...   \n0  [{'division_url': 'https://www.azstlucas.be/sp...   \n0  [{'division_url': 'https://www.azstlucas.be/sp...   \n\n                                               intro  \\\n0  Elke pasgeborene wordt - bij overnachting - bi...   \n0  Elke pasgeborene wordt - bij overnachting - bi...   \n0  Elke pasgeborene wordt - bij overnachting - bi...   \n0  Elke pasgeborene wordt - bij overnachting - bi...   \n0  Elke pasgeborene wordt - bij overnachting - bi...   \n\n                                                 toc  \\\n0  [{'link_url': '#waarom-willen-we-dat-je-baby-m...   \n0  [{'link_url': '#waarom-willen-we-dat-je-baby-m...   \n0  [{'link_url': '#waarom-willen-we-dat-je-baby-m...   \n0  [{'link_url': '#waarom-willen-we-dat-je-baby-m...   \n0  [{'link_url': '#waarom-willen-we-dat-je-baby-m...   \n\n                                                 url          scrape_date  \\\n0  https://www.azstlucas.be/onderzoek-en-behandel...  12/11/2023 15:26:50   \n0  https://www.azstlucas.be/onderzoek-en-behandel...  12/11/2023 15:26:50   \n0  https://www.azstlucas.be/onderzoek-en-behandel...  12/11/2023 15:26:50   \n0  https://www.azstlucas.be/onderzoek-en-behandel...  12/11/2023 15:26:50   \n0  https://www.azstlucas.be/onderzoek-en-behandel...  12/11/2023 15:26:50   \n\n                                      chunk_s500_o60  chunk_order  \n0  ## Waarom willen de kinderartsen dat je baby m...            0  \n0  ## Mogelijke afwijkingen\\n\\n\\n### Aangeboren h...            1  \n0  ### Infecties\\n\\n\\nVerschillende infecties wor...            2  \n0  ### Aangeboren darmafwijkingen\\n\\n\\nHet is pas...            3  \n0  De kinderarts onderzoekt je baby in normale om...            4  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>banner_title</th>\n      <th>banner_divisions</th>\n      <th>intro</th>\n      <th>toc</th>\n      <th>url</th>\n      <th>scrape_date</th>\n      <th>chunk_s500_o60</th>\n      <th>chunk_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\\n## Waarom willen de kinderartsen dat je baby...</td>\n      <td>24 uur observatie van de pasgeborene</td>\n      <td>[{'division_url': 'https://www.azstlucas.be/sp...</td>\n      <td>Elke pasgeborene wordt - bij overnachting - bi...</td>\n      <td>[{'link_url': '#waarom-willen-we-dat-je-baby-m...</td>\n      <td>https://www.azstlucas.be/onderzoek-en-behandel...</td>\n      <td>12/11/2023 15:26:50</td>\n      <td>## Waarom willen de kinderartsen dat je baby m...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>\\n## Waarom willen de kinderartsen dat je baby...</td>\n      <td>24 uur observatie van de pasgeborene</td>\n      <td>[{'division_url': 'https://www.azstlucas.be/sp...</td>\n      <td>Elke pasgeborene wordt - bij overnachting - bi...</td>\n      <td>[{'link_url': '#waarom-willen-we-dat-je-baby-m...</td>\n      <td>https://www.azstlucas.be/onderzoek-en-behandel...</td>\n      <td>12/11/2023 15:26:50</td>\n      <td>## Mogelijke afwijkingen\\n\\n\\n### Aangeboren h...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>\\n## Waarom willen de kinderartsen dat je baby...</td>\n      <td>24 uur observatie van de pasgeborene</td>\n      <td>[{'division_url': 'https://www.azstlucas.be/sp...</td>\n      <td>Elke pasgeborene wordt - bij overnachting - bi...</td>\n      <td>[{'link_url': '#waarom-willen-we-dat-je-baby-m...</td>\n      <td>https://www.azstlucas.be/onderzoek-en-behandel...</td>\n      <td>12/11/2023 15:26:50</td>\n      <td>### Infecties\\n\\n\\nVerschillende infecties wor...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>\\n## Waarom willen de kinderartsen dat je baby...</td>\n      <td>24 uur observatie van de pasgeborene</td>\n      <td>[{'division_url': 'https://www.azstlucas.be/sp...</td>\n      <td>Elke pasgeborene wordt - bij overnachting - bi...</td>\n      <td>[{'link_url': '#waarom-willen-we-dat-je-baby-m...</td>\n      <td>https://www.azstlucas.be/onderzoek-en-behandel...</td>\n      <td>12/11/2023 15:26:50</td>\n      <td>### Aangeboren darmafwijkingen\\n\\n\\nHet is pas...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>\\n## Waarom willen de kinderartsen dat je baby...</td>\n      <td>24 uur observatie van de pasgeborene</td>\n      <td>[{'division_url': 'https://www.azstlucas.be/sp...</td>\n      <td>Elke pasgeborene wordt - bij overnachting - bi...</td>\n      <td>[{'link_url': '#waarom-willen-we-dat-je-baby-m...</td>\n      <td>https://www.azstlucas.be/onderzoek-en-behandel...</td>\n      <td>12/11/2023 15:26:50</td>\n      <td>De kinderarts onderzoekt je baby in normale om...</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700299298216
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Embedding Model \n",
        "\n",
        "Hugginfacehub model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "for i in range(torch.cuda.device_count()):\n",
        "   print(torch.cuda.get_device_properties(i).name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tesla V100-PCIE-16GB\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700298810097
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models to try out\n",
        "- try out instructor with different query for doc storing and tetrieval \n",
        "- https://huggingface.co/jegormeister/robbert-v2-dutch-base-mqa-finetuned\n",
        "- https://huggingface.co/intfloat/multilingual-e5-base\n",
        "- intfloat/multilingual-e5-large\n",
        "- timpal0l/mdeberta-v3-base-squad2"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\n",
        "    'jegorkitskerkin/robbert-v2-dutch-base-mqa-finetuned', \n",
        "    cache_folder='./models/robbert-v2-dutch-base-mqa-finetuned',\n",
        "    device='cuda'\n",
        ")\n",
        "\n",
        "#Our sentences we like to encode\n",
        "sentences = list(chunks_raw_df['content'])\n",
        "\n",
        "robbert_mqa_embeddings: List[List[float]] = model.encode(\n",
        "    sentences, \n",
        "    show_progress_bar=True\n",
        ")\n",
        "print(robbert_mqa_embeddings)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/139 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e75639487ca425abdfa44aac151d86e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[[-0.33865708 -0.53614783 -0.50242066 ... -0.23327178  1.3994951\n  -0.31295717]\n [-0.33865708 -0.53614783 -0.50242066 ... -0.23327178  1.3994951\n  -0.31295717]\n [-0.33865708 -0.53614783 -0.50242066 ... -0.23327178  1.3994951\n  -0.31295717]\n ...\n [-0.1205714   0.53177935  0.14113781 ... -0.0951068   1.1831994\n  -1.0692893 ]\n [-0.1205714   0.53177935  0.14113781 ... -0.0951068   1.1831994\n  -1.0692893 ]\n [-0.1205714   0.53177935  0.14113781 ... -0.0951068   1.1831994\n  -1.0692893 ]]\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700300972104
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(robbert_mqa_embeddings)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "4444"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700300990820
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
        "\n",
        "model_kwargs = {\n",
        "    'device': 'cuda'\n",
        "}\n",
        "encode_kwargs = {\n",
        "    # 'normalize_embeddings': True,\n",
        "    'show_progress_bar': True\n",
        "}\n",
        "embeddings = HuggingFaceInstructEmbeddings(\n",
        "    model_name=\"hkunlp/instructor-xl\", \n",
        "    cache_folder='./models/model_cache_xl',\n",
        "    embed_instruction=\"Represent the Medical paragraph for retrieval: \",\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "load INSTRUCTOR_Transformer\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700301193530
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700299976608
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List \n",
        "\n",
        "l = list(chunks_raw_df['content'])\n",
        "embeddings: List[List[float]] = embeddings.embed_documents(l)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List \n\u001b[1;32m      3\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks_raw_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/langchain/embeddings/huggingface.py:171\u001b[0m, in \u001b[0;36mHuggingFaceInstructEmbeddings.embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute doc embeddings using a HuggingFace instruct model.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m instruction_pairs \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_instruction, text] \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[0;32m--> 171\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstruction_pairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mtolist()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/InstructorEmbedding/instructor.py:539\u001b[0m, in \u001b[0;36mINSTRUCTOR.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    536\u001b[0m features \u001b[38;5;241m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 539\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_value \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    542\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/InstructorEmbedding/instructor.py:278\u001b[0m, in \u001b[0;36mINSTRUCTOR_Transformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;66;03m# print('n ',n)\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m local_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[0;32m--> 278\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlocal_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m context_masks[local_idx]\u001b[38;5;241m.\u001b[39mitem(),\\\n\u001b[1;32m    279\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattention_mask[local_idx]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext_masks[local_idx]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[1;32m    280\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39msum(attention_mask[local_idx])\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext_masks[local_idx]\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    281\u001b[0m         attention_mask[local_idx][:context_masks[local_idx]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# print('forward here')\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700299968647
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def embed_str(s: str) -> np.ndarray:\n",
        "    return np.float64(embeddings.embed_query(s))\n",
        "\n",
        "def embed_df(df: pd.DataFrame, field:str) -> pd.DataFrame:\n",
        "    df[f'{field}_embedding'] = (\n",
        "        df[field].apply(embed_str)\n",
        "    )\n",
        "    return df\n",
        "\n",
        "# Read from pikle file\n",
        "chunks_processed_df = (\n",
        "    chunks_raw_df.copy(deep=True)\n",
        "    # Filter (testing)\n",
        "    # .pipe(lambda df: df.head(100))\n",
        "    .pipe(embed_df, field=\"chunk_s500_o60\")\n",
        ")\n",
        "\n",
        "chunks_processed_df.to_pickle(path='./data/chunks_processed_full.pkl')\n",
        "\n",
        "chunks_processed_df.head(15)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1699894062442
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save DF to Blob Storage for later retrieval. \n",
        "chunks_processed_df.to_pickle(path='./data/chunks_processed.pkl')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1699867727669
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}